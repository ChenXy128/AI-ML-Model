{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c950686e",
   "metadata": {},
   "source": [
    "### Task 1: Model Implementation (80% Marks)\n",
    "\n",
    "Implement your model that you want to submit by completing the following functions:\n",
    "* `__init__`: The constructor for Model class.\n",
    "* `fit`: Fit/train the model using the input data. You may perform data handling and preprocessing here before training your model.\n",
    "* `predict`: Predict using the model. If you perform data handling and preprocessing in the `fit` function, then you may want to do the same here.\n",
    "\n",
    "#### Dependencies\n",
    "\n",
    "It is crucial to note that your model may rely on specific versions of Python packages, including:\n",
    "\n",
    "* Python 3.10\n",
    "* Numpy version 1.23\n",
    "* Pandas version 1.4\n",
    "* Scikit-Learn version 1.1\n",
    "* PyTorch version 1.12\n",
    "* Torchvision version 0.13\n",
    "\n",
    "To prevent any compatibility issues or unexpected errors during the execution of your code, ensure that you are using the correct versions of these packages. You can refer to `environment.yml` for a comprehensive list of packages that are pre-installed in Coursemology and can be used by your model. Note that if you do end up using libraries that are not installed on Coursemology, you might see an error like:\n",
    "\n",
    "\"Your code failed to evaluate correctly. There might be a syntax error, or perhaps execution failed to complete within the allocated time and memory limits.\"\n",
    "\n",
    "#### Model Template\n",
    "\n",
    "Note that you should copy and paste the code below *directly* into Coursemology for submission. You should probably test the code in this notebook on your local machine before uploading to Coursemology and using up an attempt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a44b7aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, classes, drop_prob):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)  \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)  \n",
    "        self.fc1 = nn.Linear(64 * 2 * 2, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)  \n",
    "        self.fc2 = nn.Linear(64, classes)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
    "        self.max_pool = nn.MaxPool2d(2, 2)\n",
    "        self.drop = nn.Dropout2d(drop_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.drop(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.bn3(self.fc1(x))\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class DataLoaderHeler(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class Model:  \n",
    "    \"\"\"\n",
    "    This class represents an AI model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = CNN(classes=3, drop_prob=0.4)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.005)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "\n",
    "    def image_replacing_nan(self, images):\n",
    "        nan_mask = np.isnan(images)\n",
    "        means = np.nanmean(images, axis=(2, 3), keepdims=True)  \n",
    "        images[nan_mask] = np.broadcast_to(means, images.shape)[nan_mask]\n",
    "        clipped_images = np.clip(images, 0, 255)\n",
    "        return clipped_images\n",
    "        \n",
    "    \n",
    "    def standardising_images(self, images):\n",
    "        return images / 255.0\n",
    "    \n",
    "    def images_labels_filter_nan(self, images, labels):\n",
    "        not_nan_indices = ~np.isnan(labels)\n",
    "        filtered_images = images[not_nan_indices]\n",
    "        filtered_labels = labels[not_nan_indices]\n",
    "        return filtered_images, filtered_labels\n",
    "    \n",
    "\n",
    "    def data_processing(self, images, labels):\n",
    "        images_with_no_nan = self.image_replacing_nan(images)\n",
    "        images_standardized = self.standardising_images(images_with_no_nan)\n",
    "        processed_images, processed_labels = self.images_labels_filter_nan(images_standardized, labels)\n",
    "        \n",
    "        return processed_images, processed_labels\n",
    "\n",
    "    \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the model using the input data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, channel, height, width)\n",
    "            Training data.\n",
    "        y : ndarray of shape (n_samples,)\n",
    "            Target values.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns an instance of the trained model.\n",
    "        \"\"\"\n",
    "        X_processed, y_processed = self.data_processing(X, y) \n",
    "        X_processed = torch.tensor(X_processed, dtype=torch.float32)\n",
    "        y_processed = torch.tensor(y_processed, dtype=torch.long)\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.RandomAffine(degrees=5, translate=(0.1, 0.1))\n",
    "        ])\n",
    "\n",
    "        dataset = DataLoaderHeler(X_processed, y_processed, transform=transform)\n",
    "        dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "        self.model.train()\n",
    "        losses = []\n",
    "        for epoch in range(60):\n",
    "            for batch_X, batch_y in dataloader:\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(batch_X)\n",
    "                loss = self.loss_fn(output, batch_y)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                self.optimizer.step()\n",
    "                loss += loss.item()\n",
    "\n",
    "            loss = loss / len(dataloader)\n",
    "            losses.append(loss)\n",
    "            print (\"Epoch: {}, Loss: {}\".format(epoch, loss))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Use the trained model to make predictions.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, channel, height, width)\n",
    "            Input data.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        ndarray of shape (n_samples,)\n",
    "        Predicted target values per element in X.\n",
    "           \n",
    "        \"\"\"\n",
    "        # TODO: Replace the following code with your own prediction code.\n",
    "        X = self.image_replacing_nan(X)\n",
    "        X = self.standardising_images(X)\n",
    "        #print(\"X with no nan in predict:\", X)\n",
    "        X = torch.tensor(X, dtype=torch.float32) \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(X)\n",
    "            #print(\"Pred in model: \", predictions)\n",
    "            return torch.argmax(predictions, dim=1)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02178d7",
   "metadata": {},
   "source": [
    "#### Local Evaluation\n",
    "\n",
    "You may test your solution locally by running the following code. Do note that the results may not reflect your performance in Coursemology. You should not be submitting the code below in Coursemology. The code here is meant only for you to do local testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f4dd489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3064e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('data.npy', 'rb') as f:\n",
    "    data = np.load(f, allow_pickle=True).item()\n",
    "    X = data['image']\n",
    "    y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27c9fd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiaoyangchen/anaconda3/envs/cs2109s-2310-final/lib/python3.10/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.006227259058505297\n",
      "Epoch: 1, Loss: 0.015650637447834015\n",
      "Epoch: 2, Loss: 0.005333427805453539\n",
      "Epoch: 3, Loss: 0.008770504035055637\n",
      "Epoch: 4, Loss: 0.010700362734496593\n",
      "Epoch: 5, Loss: 0.006714912597090006\n",
      "Epoch: 6, Loss: 0.02091103605926037\n",
      "Epoch: 7, Loss: 0.008979168720543385\n",
      "Epoch: 8, Loss: 0.010312584228813648\n",
      "Epoch: 9, Loss: 0.015219288878142834\n",
      "Epoch: 10, Loss: 0.006562580354511738\n",
      "Epoch: 11, Loss: 0.012572119012475014\n",
      "Epoch: 12, Loss: 0.009559981524944305\n",
      "Epoch: 13, Loss: 0.01793425716459751\n",
      "Epoch: 14, Loss: 0.01622496172785759\n",
      "Epoch: 15, Loss: 0.010199349373579025\n",
      "Epoch: 16, Loss: 0.005586152896285057\n",
      "Epoch: 17, Loss: 0.007257682271301746\n",
      "Epoch: 18, Loss: 0.012815149500966072\n",
      "Epoch: 19, Loss: 0.006799270864576101\n",
      "Epoch: 20, Loss: 0.008297600783407688\n",
      "Epoch: 21, Loss: 0.010762771591544151\n",
      "Epoch: 22, Loss: 0.010082882829010487\n",
      "Epoch: 23, Loss: 0.008948263712227345\n",
      "Epoch: 24, Loss: 0.007411038503050804\n",
      "Epoch: 25, Loss: 0.012644109316170216\n",
      "Epoch: 26, Loss: 0.005731308367103338\n",
      "Epoch: 27, Loss: 0.011364287696778774\n",
      "Epoch: 28, Loss: 0.009983869269490242\n",
      "Epoch: 29, Loss: 0.011177616193890572\n",
      "Epoch: 30, Loss: 0.013074653223156929\n",
      "Epoch: 31, Loss: 0.004318718798458576\n",
      "Epoch: 32, Loss: 0.005540842190384865\n",
      "Epoch: 33, Loss: 0.007655009161680937\n",
      "Epoch: 34, Loss: 0.007155919447541237\n",
      "Epoch: 35, Loss: 0.003935894928872585\n",
      "Epoch: 36, Loss: 0.010707956738770008\n",
      "Epoch: 37, Loss: 0.007625386584550142\n",
      "Epoch: 38, Loss: 0.010501880198717117\n",
      "Epoch: 39, Loss: 0.01315212994813919\n",
      "Epoch: 40, Loss: 0.01016070693731308\n",
      "Epoch: 41, Loss: 0.0064999861642718315\n",
      "Epoch: 42, Loss: 0.0117722162976861\n",
      "Epoch: 43, Loss: 0.004533589351922274\n",
      "Epoch: 44, Loss: 0.004191542975604534\n",
      "Epoch: 45, Loss: 0.004366894718259573\n",
      "Epoch: 46, Loss: 0.00979982316493988\n",
      "Epoch: 47, Loss: 0.011399896815419197\n",
      "Epoch: 48, Loss: 0.002959456294775009\n",
      "Epoch: 49, Loss: 0.009888834320008755\n",
      "Epoch: 50, Loss: 0.021805355325341225\n",
      "Epoch: 51, Loss: 0.011753170751035213\n",
      "Epoch: 52, Loss: 0.007210631854832172\n",
      "Epoch: 53, Loss: 0.00972795207053423\n",
      "Epoch: 54, Loss: 0.013032091781497002\n",
      "Epoch: 55, Loss: 0.007489543408155441\n",
      "Epoch: 56, Loss: 0.019492950290441513\n",
      "Epoch: 57, Loss: 0.0039700958877801895\n",
      "Epoch: 58, Loss: 0.007649457082152367\n",
      "Epoch: 59, Loss: 0.004387283697724342\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 0, 0, 2,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0])\n",
      "F1 Score (macro): 0.74\n"
     ]
    }
   ],
   "source": [
    "# Split train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# Filter test data that contains no labels\n",
    "# In Coursemology, the test data is guaranteed to have labels\n",
    "nan_indices = np.argwhere(np.isnan(y_test)).squeeze()\n",
    "mask = np.ones(y_test.shape, bool)\n",
    "mask[nan_indices] = False\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "# Train and predict\n",
    "model = Model()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)\n",
    "# Evaluate model predition\n",
    "# Learn more: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "print(\"F1 Score (macro): {0:.2f}\".format(f1_score(y_test, y_pred, average='macro'))) # You may encounter errors, you are expected to figure out what's the issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16861aef",
   "metadata": {},
   "source": [
    "#### Grading Scheme\n",
    "\n",
    "Your code implementation will be graded based on its performance ([**Macro F1 Score**](http://iamirmasoud.com/2022/06/19/understanding-micro-macro-and-weighted-averages-for-scikit-learn-metrics-in-multi-class-classification-with-example/)*) in the contest. Your model will be trained with the data that we provided you with this assesment. We will use score cutoffs that we will decide after the contest to determine your marks.\n",
    "\n",
    "The performance of your model will be determined by a separate test data set, drawn from the same population as the training set, but not provided to you earlier. The marks you will receive will depend on the **Macro F1 Score** of the predictions:\n",
    "\n",
    "* If your score is above the mean or median, you can expect to receive decent marks. \n",
    "* If your score is higher than the 75th percentile, you are likely to receive good marks. \n",
    "* If you achieve a score above the 90th percentile (top 10%), you will likely receive full marks.\n",
    "\n",
    "Throughout the contest, we will provide periodic updates on the distribution of the score of student submissions in the official forum thread (see Overview) based on the **public test case**, which test the performance of the model on **a small subset of data from the hidden test data**. You can use these updates to estimate your relative standing, compared to your peers. \n",
    "\n",
    "<b>*) Macro F1 Score:</b> F1 score for multi-class classification computed by taking the average of all the per-class F1 score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c79c17",
   "metadata": {},
   "source": [
    "### Task 2: Scratch Pad (20% Marks)\n",
    "\n",
    "Fill up the `scratchpad.ipynb` with your working. \n",
    "\n",
    "In the **\"Report\" section**, write a report that explain the thought process behind your solution, and convince us that you have understood the concepts taught in class and can apply them. The report should cover data exploration and preparation, data preprocessing, modeling, and evaluation. The final solution and any alternative approaches that were tried but did not work may also be documented. The length of the report should be approximately equivalent to **1-2 pages of A4 paper (up to 1,000 words)**.\n",
    "\n",
    "#### Grading Scheme\n",
    "\n",
    "The report will be graded based on the reasonability and soundness of the approach you take, your understanding of the data, and your final solution. If you do not make any errors in your approach, reasoning/understanding, and conclusion, you can expect to receive full marks. This part is meant to be \"standard\", and is only for us to do a quick sanity check that you actually did the work required to come up with the model you submitted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b658b4",
   "metadata": {},
   "source": [
    "### Submission\n",
    "\n",
    "Once you are done, please submit your work to Coursemology, by copying the right snippets of code into the corresponding box that says 'Model Implementation', and click 'Save Draft'. You can still make changes after you save your submission.\n",
    "\n",
    "When submitting your model, the `fit` function will be called to train your model with the **data that we have provided you**. Due to the inherent stochasticity of the training process, **your model's performance may vary across different runs**. To ensure deterministic results, you can set a fixed random seed in your code. After the training is completed, the `predict` function will be used to evaluate your model. The evaluation of your model will be based on two test cases: \n",
    "1. **Public test cases, containing a small portion of the test data**, that allows you to **estimate** your score. \n",
    "2. **Evaluation test cases containing the remaining test data** (which you will not be able to see) by which we will evaluate your model. \n",
    "\n",
    "Your score in the public test case may not reflect your actual score. **Note that running all test cases can take up to 5 minutes to complete, and you have a maximum of 20 attempts.** We only provide you with a limited number of tries because we do not want you to spam our autograder. \n",
    "\n",
    "Finally, when you are satisfied with your submission, you can finalize it by clicking \"Finalize submission.\". <span style=\"color:red\">**Note that once you have finalized your submission, it is considered to be submitted for grading, and no further changes can be made**.</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
