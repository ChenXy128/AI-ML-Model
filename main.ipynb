{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c950686e",
   "metadata": {},
   "source": [
    "### Task 1: Model Implementation (80% Marks)\n",
    "\n",
    "Implement your model that you want to submit by completing the following functions:\n",
    "* `__init__`: The constructor for Model class.\n",
    "* `fit`: Fit/train the model using the input data. You may perform data handling and preprocessing here before training your model.\n",
    "* `predict`: Predict using the model. If you perform data handling and preprocessing in the `fit` function, then you may want to do the same here.\n",
    "\n",
    "#### Dependencies\n",
    "\n",
    "It is crucial to note that your model may rely on specific versions of Python packages, including:\n",
    "\n",
    "* Python 3.10\n",
    "* Numpy version 1.23\n",
    "* Pandas version 1.4\n",
    "* Scikit-Learn version 1.1\n",
    "* PyTorch version 1.12\n",
    "* Torchvision version 0.13\n",
    "\n",
    "To prevent any compatibility issues or unexpected errors during the execution of your code, ensure that you are using the correct versions of these packages. You can refer to `environment.yml` for a comprehensive list of packages that are pre-installed in Coursemology and can be used by your model. Note that if you do end up using libraries that are not installed on Coursemology, you might see an error like:\n",
    "\n",
    "\"Your code failed to evaluate correctly. There might be a syntax error, or perhaps execution failed to complete within the allocated time and memory limits.\"\n",
    "\n",
    "#### Model Template\n",
    "\n",
    "Note that you should copy and paste the code below *directly* into Coursemology for submission. You should probably test the code in this notebook on your local machine before uploading to Coursemology and using up an attempt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a44b7aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, classes, drop_prob):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)  \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)  \n",
    "        self.fc1 = nn.Linear(64 * 2 * 2, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)  \n",
    "        self.fc2 = nn.Linear(64, classes)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.1)\n",
    "        self.max_pool = nn.MaxPool2d(2, 2)\n",
    "        self.drop = nn.Dropout2d(drop_prob)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.drop(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.bn3(self.fc1(x))\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class DataLoaderHeler(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        label = self.labels[index]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "class Model:  \n",
    "    \"\"\"\n",
    "    This class represents an AI model.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = CNN(classes=3, drop_prob=0.4)\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=0.005)\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "\n",
    "    def image_replacing_nan(self, images):\n",
    "        nan_mask = np.isnan(images)\n",
    "        means = np.nanmean(images, axis=(2, 3), keepdims=True)  \n",
    "        images[nan_mask] = np.broadcast_to(means, images.shape)[nan_mask]\n",
    "        clipped_images = np.clip(images, 0, 255)\n",
    "        return clipped_images\n",
    "        \n",
    "    \n",
    "    def standardising_images(self, images):\n",
    "        return images / 255.0\n",
    "    \n",
    "    def images_labels_filter_nan(self, images, labels):\n",
    "        not_nan_indices = ~np.isnan(labels)\n",
    "        filtered_images = images[not_nan_indices]\n",
    "        filtered_labels = labels[not_nan_indices]\n",
    "        return filtered_images, filtered_labels\n",
    "    \n",
    "\n",
    "    def data_processing(self, images, labels):\n",
    "        images_with_no_nan = self.image_replacing_nan(images)\n",
    "        images_standardized = self.standardising_images(images_with_no_nan)\n",
    "        processed_images, processed_labels = self.images_labels_filter_nan(images_standardized, labels)\n",
    "        \n",
    "        return processed_images, processed_labels\n",
    "\n",
    "    \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the model using the input data.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, channel, height, width)\n",
    "            Training data.\n",
    "        y : ndarray of shape (n_samples,)\n",
    "            Target values.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns an instance of the trained model.\n",
    "        \"\"\"\n",
    "        X_processed, y_processed = self.data_processing(X, y) \n",
    "        X_processed = torch.tensor(X_processed, dtype=torch.float32)\n",
    "        y_processed = torch.tensor(y_processed, dtype=torch.long)\n",
    "        \n",
    "        transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.RandomAffine(degrees=5, translate=(0.1, 0.1))\n",
    "        ])\n",
    "\n",
    "        dataset = DataLoaderHeler(X_processed, y_processed, transform=transform)\n",
    "        dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "        self.model.train()\n",
    "        losses = []\n",
    "        for epoch in range(60):\n",
    "            for batch_X, batch_y in dataloader:\n",
    "                self.optimizer.zero_grad()\n",
    "                output = self.model(batch_X)\n",
    "                loss = self.loss_fn(output, batch_y)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                self.optimizer.step()\n",
    "                loss += loss.item()\n",
    "\n",
    "            loss = loss / len(dataloader)\n",
    "            losses.append(loss)\n",
    "            print (\"Epoch: {}, Loss: {}\".format(epoch, loss))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Use the trained model to make predictions.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of shape (n_samples, channel, height, width)\n",
    "            Input data.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        ndarray of shape (n_samples,)\n",
    "        Predicted target values per element in X.\n",
    "           \n",
    "        \"\"\"\n",
    "        # TODO: Replace the following code with your own prediction code.\n",
    "        X = self.image_replacing_nan(X)\n",
    "        X = self.standardising_images(X)\n",
    "        #print(\"X with no nan in predict:\", X)\n",
    "        X = torch.tensor(X, dtype=torch.float32) \n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = self.model(X)\n",
    "            #print(\"Pred in model: \", predictions)\n",
    "            return torch.argmax(predictions, dim=1)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02178d7",
   "metadata": {},
   "source": [
    "#### Local Evaluation\n",
    "\n",
    "You may test your solution locally by running the following code. Do note that the results may not reflect your performance in Coursemology. You should not be submitting the code below in Coursemology. The code here is meant only for you to do local testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f4dd489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3064e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('data.npy', 'rb') as f:\n",
    "    data = np.load(f, allow_pickle=True).item()\n",
    "    X = data['image']\n",
    "    y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c9fd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# Filter test data that contains no labels\n",
    "# In Coursemology, the test data is guaranteed to have labels\n",
    "nan_indices = np.argwhere(np.isnan(y_test)).squeeze()\n",
    "mask = np.ones(y_test.shape, bool)\n",
    "mask[nan_indices] = False\n",
    "X_test = X_test[mask]\n",
    "y_test = y_test[mask]\n",
    "# Train and predict\n",
    "model = Model()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(y_pred)\n",
    "# Evaluate model predition\n",
    "# Learn more: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "print(\"F1 Score (macro): {0:.2f}\".format(f1_score(y_test, y_pred, average='macro'))) # You may encounter errors, you are expected to figure out what's the issue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
